{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /Users/ffr/Desktop/10701/project\n",
      "Tap-to-Music path: /Users/ffr/Desktop/10701/project/Tap-to-Music\n",
      "Workspace contents: ['.DS_Store', 'hannds', 'features', '__pycache__', 'maestro-v3.0.0', '10701project.ipynb', 'features...', 'left_right_data.py', '.vscode', 'outputs', 'lightning_logs', 'Tap-to-Music']\n"
     ]
    }
   ],
   "source": [
    "# Local setup: point to the Tap-to-Music repo and project root (no Colab drive needed)\n",
    "# %pip install -q torch pytorch-lightning pretty_midi  # uncomment if deps are missing\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "TAP_TO_MUSIC_PATH = PROJECT_ROOT / \"../Tap-to-Music\"  # set to your local clone of https://github.com/lynnzYe/Tap-to-Music\n",
    "\n",
    "if not TAP_TO_MUSIC_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Tap-to-Music repo not found at {TAP_TO_MUSIC_PATH}. Clone it locally first.\")\n",
    "\n",
    "sys.path.append(str(TAP_TO_MUSIC_PATH))\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"Working directory: {PROJECT_ROOT}\")\n",
    "print(\"Tap-to-Music path:\", TAP_TO_MUSIC_PATH)\n",
    "print(\"Workspace contents:\", [p.name for p in PROJECT_ROOT.iterdir()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1737200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a DataModule backed by Tap-to-Music RangeDataset reading unconditional PKLs\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from ttm.data_preparation.dataset import RangeDataset\n",
    "\n",
    "FEATURE_FOLDER = PROJECT_ROOT / \"features\"\n",
    "\n",
    "class UncondRangeDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, feature_folder: str, batch_size: int = 32, num_workers: int = 0):\n",
    "        super().__init__()\n",
    "        self.feature_folder = feature_folder\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        for split in [\"train\", \"validation\"]:\n",
    "            path = os.path.join(self.feature_folder, f\"unconditional-{split}.pkl\")\n",
    "            if not os.path.exists(path):\n",
    "                raise FileNotFoundError(f\"Missing {path}; run FeaturePreparation(feature='unconditional') to generate.\")\n",
    "        # Use RangeDataset but point to unconditional PKLs\n",
    "        self.train_ds = RangeDataset(self.feature_folder, \"train\", feature_type=\"unconditional\")\n",
    "        self.val_ds = RangeDataset(self.feature_folder, \"validation\", feature_type=\"unconditional\")\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "range_data_module = UncondRangeDataModule(str(FEATURE_FOLDER), batch_size=32, num_workers=0)\n",
    "# Use this for training below\n",
    "data_module = range_data_module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99f6b968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range-aware LSTM over full 4-dim features; predicts next pitch, velocity, and duration\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ttm.config import MAX_PIANO_PITCH, MIN_PIANO_PITCH\n",
    "\n",
    "class RangeTapLSTM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pitch_vocab: int = MAX_PIANO_PITCH + 1,\n",
    "        pitch_emb_dim: int = 32,\n",
    "        range_vocab: int = 3,\n",
    "        range_emb_dim: int = 3,\n",
    "        hidden: int = 128,\n",
    "        layers: int = 2,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.pitch_emb = nn.Embedding(pitch_vocab + 1, pitch_emb_dim, padding_idx=pitch_vocab)\n",
    "        self.range_emb = nn.Embedding(range_vocab if range_vocab is not None else len(range_bounds), range_emb_dim)\n",
    "        self.input_linear = nn.Linear(pitch_emb_dim + range_emb_dim + 2, hidden)\n",
    "        self.lstm = nn.LSTM(hidden, hidden, num_layers=layers, batch_first=True, dropout=dropout)\n",
    "        self.pitch_head = nn.Linear(hidden, pitch_vocab + 1)\n",
    "        self.vel_head = nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(), nn.Linear(hidden, 1))\n",
    "        self.dur_head = nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(), nn.Linear(hidden, 1))\n",
    "\n",
    "    def forward(self, feats: torch.Tensor, range_ids: torch.Tensor):\n",
    "        \"\"\"\n",
    "        feats: (B, T, 4) = [pitch, log_dt, log_dur, velocity]\n",
    "        range_ids: (B,) int\n",
    "        returns pitch_logits (B,T,V), vel_pred (B,T), dur_pred (B,T)\n",
    "        \"\"\"\n",
    "        B, T, _ = feats.shape\n",
    "        pitch_idx = feats[..., 0].long().clamp(min=0, max=MAX_PIANO_PITCH)\n",
    "        log_dt = feats[..., 1]\n",
    "        log_dur = feats[..., 2]\n",
    "        vel = feats[..., 3]\n",
    "\n",
    "        pitch_embed = self.pitch_emb(pitch_idx)\n",
    "        range_embed = self.range_emb(range_ids).unsqueeze(1).expand(B, T, -1)\n",
    "        x = torch.cat([pitch_embed, range_embed, log_dt.unsqueeze(-1), log_dur.unsqueeze(-1)], dim=-1)\n",
    "        x = self.input_linear(x)\n",
    "        out, _ = self.lstm(x)\n",
    "\n",
    "        pitch_logits = self.pitch_head(out)\n",
    "        vel_pred = self.vel_head(out).squeeze(-1)\n",
    "        dur_pred = F.softplus(self.dur_head(out).squeeze(-1))  # keep durations positive\n",
    "        return pitch_logits, vel_pred, dur_pred\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate_next(self, feats: torch.Tensor, range_id: int, temperature: float = 1.0):\n",
    "        self.eval()\n",
    "        logits, vel_pred, dur_pred = self(feats.unsqueeze(0), torch.tensor([range_id], device=feats.device))\n",
    "        next_pitch_logits = logits[:, -1, :] / temperature\n",
    "        probs = F.softmax(next_pitch_logits, dim=-1)\n",
    "        next_pitch = torch.multinomial(probs, num_samples=1).squeeze()\n",
    "        next_vel = vel_pred[:, -1].squeeze().clamp(0, 127)\n",
    "        next_dur = dur_pred[:, -1].squeeze()\n",
    "        return next_pitch.item(), next_vel.item(), next_dur.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_default_dtype(torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RangeTapModule(pl.LightningModule):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.model = RangeTapLSTM(**kwargs)\n",
    "        self.lr = 1e-3\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        feats, labels, range_ids = batch  # adjust to your dataloader format\n",
    "        pitch_logits, vel_pred, dur_pred = self.model(feats, range_ids)\n",
    "        ce = F.cross_entropy(pitch_logits.view(-1, pitch_logits.size(-1)),\n",
    "                             labels.view(-1), ignore_index=88)\n",
    "        vel_loss = F.mse_loss(vel_pred, feats[..., 3])  # or your target\n",
    "        dur_loss = F.mse_loss(dur_pred, feats[..., 2])\n",
    "        loss = ce + vel_loss + dur_loss\n",
    "        self.log_dict({\"train_loss\": loss})\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f8ad619",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pytorch_lightning/trainer/configuration_validator.py:68: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "\n",
      "  | Name  | Type         | Params | Mode \n",
      "-----------------------------------------------\n",
      "0 | model | RangeTapLSTM | 320 K  | train\n",
      "-----------------------------------------------\n",
      "320 K     Trainable params\n",
      "0         Non-trainable params\n",
      "320 K     Total params\n",
      "1.280     Total estimated model params size (MB)\n",
      "14        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /Users/ffr/Desktop/10701/project/features/unconditional-train.pkl\n",
      "Loading /Users/ffr/Desktop/10701/project/features/unconditional-validation.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f99f82251ab47e392acc4edeefc5e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 5 and the array at index 1 has size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      6\u001b[39m module = RangeTapModule()\n\u001b[32m      7\u001b[39m trainer = Trainer(\n\u001b[32m      8\u001b[39m     max_epochs=\u001b[32m5\u001b[39m,\n\u001b[32m      9\u001b[39m     accelerator=\u001b[33m\"\u001b[39m\u001b[33mgpu\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmps\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     log_every_n_steps=\u001b[32m10\u001b[39m,\n\u001b[32m     13\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrange_data_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:560\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    558\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py:49\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainer.strategy.launcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     48\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[32m     52\u001b[39m     _call_teardown_hook(trainer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:598\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    591\u001b[39m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    592\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    593\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    594\u001b[39m     ckpt_path,\n\u001b[32m    595\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    596\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    597\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m598\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n\u001b[32m    601\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:1011\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1006\u001b[39m \u001b[38;5;28mself\u001b[39m._signal_connector.register_signal_handlers()\n\u001b[32m   1008\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1011\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1016\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: trainer tearing down\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:1055\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1053\u001b[39m         \u001b[38;5;28mself\u001b[39m._run_sanity_check()\n\u001b[32m   1054\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1055\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1056\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.state\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    215\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end()\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:458\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    456\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.trainer.profiler.profile(\u001b[33m\"\u001b[39m\u001b[33mrun_training_epoch\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    457\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m458\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pytorch_lightning/loops/training_epoch_loop.py:152\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done:\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m         \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pytorch_lightning/loops/training_epoch_loop.py:310\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    309\u001b[39m     dataloader_iter = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     batch, _, __ = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m     \u001b[38;5;66;03m# TODO: we should instead use the batch_idx returned by the fetcher, however, that will require saving the\u001b[39;00m\n\u001b[32m    312\u001b[39m     \u001b[38;5;66;03m# fetcher state so that the batch_idx is correct after restarting\u001b[39;00m\n\u001b[32m    313\u001b[39m     batch_idx = \u001b[38;5;28mself\u001b[39m.batch_idx + \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pytorch_lightning/loops/fetchers.py:134\u001b[39m, in \u001b[36m_PrefetchDataFetcher.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    131\u001b[39m         \u001b[38;5;28mself\u001b[39m.done = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batches\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done:\n\u001b[32m    133\u001b[39m     \u001b[38;5;66;03m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     batch = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__next__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# the iterator is empty\u001b[39;00m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pytorch_lightning/loops/fetchers.py:61\u001b[39m, in \u001b[36m_DataFetcher.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28mself\u001b[39m._start_profiler()\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     batch = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28mself\u001b[39m.done = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pytorch_lightning/utilities/combined_loader.py:341\u001b[39m, in \u001b[36mCombinedLoader.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> _ITERATOR_RETURN:\n\u001b[32m    340\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m     out = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    342\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._iterator, _Sequential):\n\u001b[32m    343\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pytorch_lightning/utilities/combined_loader.py:78\u001b[39m, in \u001b[36m_MaxSizeCycle.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m         out[i] = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28mself\u001b[39m._consumed[i] = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:790\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    789\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    792\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/10701/project/Tap-to-Music/ttm/data_preparation/dataset.py:140\u001b[39m, in \u001b[36mRangeDataset.__getitem__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    138\u001b[39m range_value = piece_range[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(piece_range, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (piece_range \u001b[38;5;28;01mif\u001b[39;00m piece_range \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m)\n\u001b[32m    139\u001b[39m pad_row = np.array([[MAX_PIANO_PITCH + \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, range_value]])\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m note_sequence = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpad_row\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnote_sequence\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m annotation = np.concatenate([np.array([labels[start_idx][\u001b[32m0\u001b[39m]]), annotation], axis=\u001b[32m0\u001b[39m)\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.split != \u001b[33m'\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[31mValueError\u001b[39m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 5 and the array at index 1 has size 4"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "module = RangeTapModule()\n",
    "trainer = Trainer(\n",
    "    max_epochs=5,\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"mps\",\n",
    "    devices=1,\n",
    "    gradient_clip_val=1.0,\n",
    "    log_every_n_steps=10,\n",
    ")\n",
    "trainer.fit(module, datamodule=range_data_module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15b6651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster-aware LSTM conditioned on per-sequence median (5th feature column)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ttm.config import MAX_PIANO_PITCH, MIN_PIANO_PITCH\n",
    "\n",
    "class ClusterTapLSTM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pitch_vocab: int = MAX_PIANO_PITCH + 1,\n",
    "        pitch_emb_dim: int = 32,\n",
    "        hidden: int = 128,\n",
    "        layers: int = 2,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Expect feats shape (B, T, 5): [pitch, log_dt, log_dur, velocity, median]\n",
    "        self.pitch_emb = nn.Embedding(pitch_vocab + 1, pitch_emb_dim, padding_idx=pitch_vocab)\n",
    "        self.input_linear = nn.Linear(pitch_emb_dim + 4, hidden)\n",
    "        self.lstm = nn.LSTM(hidden, hidden, num_layers=layers, batch_first=True, dropout=dropout)\n",
    "        self.pitch_head = nn.Linear(hidden, pitch_vocab + 1)\n",
    "        self.vel_head = nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(), nn.Linear(hidden, 1))\n",
    "        self.dur_head = nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(), nn.Linear(hidden, 1))\n",
    "\n",
    "    def forward(self, feats: torch.Tensor):\n",
    "        \"\"\"\n",
    "        feats: (B, T, 5) = [pitch, log_dt, log_dur, velocity, median]\n",
    "        Returns pitch_logits (B,T,V), vel_pred (B,T), dur_pred (B,T)\n",
    "        \"\"\"\n",
    "        B, T, _ = feats.shape\n",
    "        pitch_idx = feats[..., 0].long().clamp(min=0, max=MAX_PIANO_PITCH)\n",
    "        log_dt = feats[..., 1]\n",
    "        log_dur = feats[..., 2]\n",
    "        vel = feats[..., 3]\n",
    "        median = feats[..., 4]\n",
    "\n",
    "        pitch_embed = self.pitch_emb(pitch_idx)\n",
    "        x = torch.cat([\n",
    "            pitch_embed,\n",
    "            log_dt.unsqueeze(-1),\n",
    "            log_dur.unsqueeze(-1),\n",
    "            vel.unsqueeze(-1),\n",
    "            median.unsqueeze(-1),\n",
    "        ], dim=-1)\n",
    "        x = self.input_linear(x)\n",
    "        out, _ = self.lstm(x)\n",
    "\n",
    "        pitch_logits = self.pitch_head(out)\n",
    "        vel_pred = self.vel_head(out).squeeze(-1)\n",
    "        dur_pred = F.softplus(self.dur_head(out).squeeze(-1))\n",
    "        return pitch_logits, vel_pred, dur_pred\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate_next(self, feats: torch.Tensor, temperature: float = 1.0):\n",
    "        \"\"\"Generate next note conditioned on the provided sequence (expects median in column 4).\"\"\"\n",
    "        self.eval()\n",
    "        logits, vel_pred, dur_pred = self(feats.unsqueeze(0))\n",
    "        next_pitch_logits = logits[:, -1, :] / temperature\n",
    "        probs = F.softmax(next_pitch_logits, dim=-1)\n",
    "        next_pitch = torch.multinomial(probs, num_samples=1).squeeze()\n",
    "        next_vel = vel_pred[:, -1].squeeze().clamp(0, 127)\n",
    "        next_dur = dur_pred[:, -1].squeeze()\n",
    "        return next_pitch.item(), next_vel.item(), next_dur.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab2edb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ClusterDataModule: wraps median-conditioned ClusterDataset (5-col features with median in col 4)\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from ttm.config import config\n",
    "from ttm.data_preparation.dataset import ClusterDataset\n",
    "\n",
    "class ClusterDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir: str, batch_size: int = None, num_workers: int = None):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size or config.get('unconditional', {}).get('batch_size', 16)\n",
    "        self.num_workers = num_workers or config.get('unconditional', {}).get('num_workers', 0)\n",
    "\n",
    "    def _ds(self, split: str):\n",
    "        # ClusterDataset holds (features, labels, median) tuples; features include median in column 4\n",
    "        return ClusterDataset(self.data_dir, split, feature_type='unconditional')\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self._ds('train'),\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            persistent_workers=self.num_workers > 0,\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self._ds('validation'),\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            persistent_workers=self.num_workers > 0,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self._ds('test'),\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            persistent_workers=self.num_workers > 0,\n",
    "            drop_last=False,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c235197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing left: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1276/1276 [01:07<00:00, 18.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1276 samples to features/hannds_left.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing right: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1276/1276 [00:53<00:00, 23.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1276 samples to features/hannds_right.pkl\n"
     ]
    }
   ],
   "source": [
    "# Generate PKLs from split HANNDs left/right MIDIs\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from ttm.data_preparation.utils import get_note_sequence_from_midi, midi_to_tap\n",
    "\n",
    "left_dir = Path('outputs/hannds_split/left')\n",
    "right_dir = Path('outputs/hannds_split/right')\n",
    "output_dir = Path('features')  # same folder as unconditional-*.pkl\n",
    "\n",
    "\n",
    "def midi_dir_to_pkl(midi_root: Path, out_path: Path):\n",
    "    midi_paths = sorted([p for p in midi_root.rglob('*') if p.suffix.lower() in {'.mid', '.midi'}])\n",
    "    data = []\n",
    "    for midi_path in tqdm(midi_paths, desc=f'Processing {midi_root.name}'):\n",
    "        try:\n",
    "            notes = get_note_sequence_from_midi(midi_path)\n",
    "            feats, labels = midi_to_tap(notes)\n",
    "            data.append((feats, labels))\n",
    "        except Exception as exc:\n",
    "            print(f'Skip {midi_path}: {exc}')\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    pickle.dump(data, open(out_path, 'wb'))\n",
    "    print(f'Saved {len(data)} samples to {out_path}')\n",
    "\n",
    "midi_dir_to_pkl(left_dir, output_dir / 'hannds_left.pkl')\n",
    "midi_dir_to_pkl(right_dir, output_dir / 'hannds_right.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0499c023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ClusterAug PKL: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2578/2578 [02:02<00:00, 21.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2578 samples to features/hannds_cluster.pkl\n"
     ]
    }
   ],
   "source": [
    "# Build a single ClusterAugmentation PKL from HANNDs-split MIDIs (left/right combined)\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from ttm.data_preparation.utils import get_note_sequence_from_midi, midi_to_tap\n",
    "from ttm.data_preparation.data_augmentation import ClusterAugmentation\n",
    "\n",
    "split_root = Path('outputs/hannds_split')\n",
    "output_dir = Path('features')\n",
    "out_path = output_dir / 'hannds_cluster.pkl'\n",
    "\n",
    "cluster_aug = ClusterAugmentation()\n",
    "\n",
    "midi_paths = [p for p in split_root.rglob('*') if p.suffix.lower() in {'.mid', '.midi'}]\n",
    "data = []\n",
    "for midi_path in tqdm(sorted(midi_paths), desc='ClusterAug PKL'):\n",
    "    try:\n",
    "        notes = get_note_sequence_from_midi(midi_path)\n",
    "        feats, labels = midi_to_tap(notes)\n",
    "        feats_aug, labels_aug, median_info = cluster_aug(feats, labels)\n",
    "        data.append((feats_aug, labels_aug, median_info))\n",
    "    except Exception as exc:\n",
    "        print(f'Skip {midi_path}: {exc}')\n",
    "\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "pickle.dump(data, open(out_path, 'wb'))\n",
    "print(f'Saved {len(data)} samples to {out_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b73581be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded samples: 2578\n",
      "val ce 3.7939863204956055 val bce 0.004972664639353752\n",
      "val ce 3.4566445350646973 val bce 0.0033888458274304867\n",
      "val ce 3.321607828140259 val bce 0.002891015028581023\n",
      "val ce 3.2729179859161377 val bce 0.0010837360750883818\n",
      "val ce 3.2381386756896973 val bce 0.0007364661432802677\n",
      "val ce 3.2002110481262207 val bce 0.0005740937776863575\n",
      "val ce 3.148324489593506 val bce 0.0011368109844624996\n",
      "val ce 3.04152250289917 val bce 0.001097196713089943\n",
      "val ce 2.9973466396331787 val bce 0.0007472229190170765\n",
      "val ce 2.9728150367736816 val bce 0.00044573377817869186\n",
      "val ce 2.978398561477661 val bce 0.00043291784822940826\n",
      "val ce 2.9560670852661133 val bce 0.0003445935435593128\n",
      "val ce 2.934034585952759 val bce 0.00021225400269031525\n",
      "val ce 2.9147841930389404 val bce 0.00024826545268297195\n",
      "val ce 2.903575897216797 val bce 0.00021154293790459633\n",
      "val ce 2.8765547275543213 val bce 0.00012388359755277634\n",
      "val ce 2.8477938175201416 val bce 0.00011513056233525276\n",
      "val ce 2.849213123321533 val bce 0.00012091128155589104\n",
      "val ce 2.840683698654175 val bce 0.00010925717651844025\n",
      "val ce 2.8327808380126953 val bce 9.192060679197311e-05\n",
      "val ce 2.8207316398620605 val bce 5.9167854487895966e-05\n",
      "val ce 2.822556734085083 val bce 7.212767377495766e-05\n",
      "val ce 2.816826343536377 val bce 6.969226524233818e-05\n",
      "val ce 2.8187947273254395 val bce 5.885446444153786e-05\n",
      "val ce 2.815727472305298 val bce 6.728200241923332e-05\n",
      "val ce 2.8067898750305176 val bce 3.816327080130577e-05\n",
      "val ce 2.797736883163452 val bce 3.957701846957207e-05\n",
      "val ce 2.8029870986938477 val bce 4.148436710238457e-05\n",
      "val ce 2.7972798347473145 val bce 4.9363356083631516e-05\n",
      "val ce 2.791863441467285 val bce 3.728363662958145e-05\n",
      "val ce 2.7902672290802 val bce 2.913316711783409e-05\n",
      "val ce 2.7794201374053955 val bce 2.5058165192604065e-05\n",
      "val ce 2.770597457885742 val bce 2.6035122573375702e-05\n",
      "val ce 2.7735440731048584 val bce 2.8123613446950912e-05\n",
      "val ce 2.779075860977173 val bce 2.0743347704410553e-05\n",
      "val ce 2.7679052352905273 val bce 1.8962658941745758e-05\n",
      "val ce 2.7829158306121826 val bce 1.9867438822984695e-05\n",
      "val ce 2.7776145935058594 val bce 2.138270065188408e-05\n",
      "val ce 2.7554426193237305 val bce 2.501998096704483e-05\n",
      "val ce 2.75917387008667 val bce 1.6408972442150116e-05\n",
      "val ce 2.758753776550293 val bce 1.6022473573684692e-05\n",
      "val ce 2.7559573650360107 val bce 2.0601321011781693e-05\n",
      "val ce 2.7588462829589844 val bce 1.3243407011032104e-05\n",
      "val ce 2.7681548595428467 val bce 1.1730939149856567e-05\n",
      "val ce 2.753114938735962 val bce 1.4359597116708755e-05\n",
      "val ce 2.7637789249420166 val bce 1.241639256477356e-05\n",
      "val ce 2.748300790786743 val bce 1.299288123846054e-05\n",
      "val ce 2.742255449295044 val bce 1.739896833896637e-05\n",
      "val ce 2.745931625366211 val bce 1.1358410120010376e-05\n",
      "val ce 2.739807605743408 val bce 1.1882279068231583e-05\n"
     ]
    }
   ],
   "source": [
    "# Train a hand-aware Cluster LSTM on hannds_cluster.pkl (pitch + hand flag + medians)\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from ttm.config import MIN_PIANO_PITCH, MAX_PIANO_PITCH\n",
    "\n",
    "pkl_path = Path('features/hannds_cluster.pkl')\n",
    "raw = pickle.load(open(pkl_path, 'rb'))\n",
    "print('Loaded samples:', len(raw))\n",
    "\n",
    "max_len = 128\n",
    "\n",
    "class ClusterHandDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        feats, labels, median_info = self.data[idx]\n",
    "        # truncate\n",
    "        feats = feats[:max_len]\n",
    "        labels = labels[:max_len]\n",
    "        # ensure 8 columns (pitch, dt, dur, vel, median, hand, left_med, right_med)\n",
    "        if feats.shape[1] < 8:\n",
    "            pad_cols = 8 - feats.shape[1]\n",
    "            feats = np.concatenate([feats, np.zeros((len(feats), pad_cols))], axis=1)\n",
    "        # normalize pitch to 0..88\n",
    "        feats = feats.copy()\n",
    "        feats[:, 0] = np.clip(feats[:, 0] - MIN_PIANO_PITCH, 0, 88)\n",
    "        labels = labels - MIN_PIANO_PITCH\n",
    "        # pad sequence\n",
    "        if len(feats) < max_len:\n",
    "            pad_len = max_len - len(feats)\n",
    "            pad_row = np.zeros((1, feats.shape[1]))\n",
    "            pad_row[0, 0] = 88\n",
    "            feats = np.concatenate([feats, np.repeat(pad_row, pad_len, axis=0)], axis=0)\n",
    "            label_pad = np.full(pad_len, 88)\n",
    "            labels = np.concatenate([labels, label_pad])\n",
    "        hand_labels = feats[:, 5].copy()\n",
    "        return torch.tensor(feats, dtype=torch.float32), torch.tensor(labels, dtype=torch.long), torch.tensor(hand_labels, dtype=torch.float32)\n",
    "\n",
    "# simple split\n",
    "split_idx = int(0.9 * len(raw))\n",
    "train_ds = ClusterHandDataset(raw[:split_idx])\n",
    "val_ds = ClusterHandDataset(raw[split_idx:])\n",
    "train_dl = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=8)\n",
    "\n",
    "class ClusterHandLSTM(nn.Module):\n",
    "    def __init__(self, pitch_vocab=MAX_PIANO_PITCH+1, pitch_emb_dim=32, hidden=128, layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.pitch_emb = nn.Embedding(pitch_vocab+1, pitch_emb_dim, padding_idx=pitch_vocab)\n",
    "        # scalars: dt, dur, vel, median, hand, left_med, right_med = 7\n",
    "        self.input_linear = nn.Linear(pitch_emb_dim + 7, hidden)\n",
    "        self.lstm = nn.LSTM(hidden, hidden, num_layers=layers, batch_first=True, dropout=dropout)\n",
    "        self.pitch_head = nn.Linear(hidden, pitch_vocab+1)\n",
    "        self.hand_head = nn.Linear(hidden, 1)\n",
    "    def forward(self, x):\n",
    "        pitch_idx = x[...,0].long().clamp(0, MAX_PIANO_PITCH)\n",
    "        scalars = x[...,1:8]\n",
    "        pitch_embed = self.pitch_emb(pitch_idx)\n",
    "        h = torch.cat([pitch_embed, scalars], dim=-1)\n",
    "        h = self.input_linear(h)\n",
    "        out,_ = self.lstm(h)\n",
    "        pitch_logits = self.pitch_head(out)\n",
    "        hand_logits = self.hand_head(out).squeeze(-1)\n",
    "        return pitch_logits, hand_logits\n",
    "\n",
    "model = ClusterHandLSTM()\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    for feats, labels, hand in train_dl:\n",
    "        optim.zero_grad()\n",
    "        pitch_logits, hand_logits = model(feats)\n",
    "        ce = F.cross_entropy(pitch_logits.view(-1, pitch_logits.size(-1)), labels.view(-1), ignore_index=88)\n",
    "        bce = F.binary_cross_entropy_with_logits(hand_logits.view(-1), hand.view(-1))\n",
    "        loss = ce + 0.1 * bce\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        feats, labels, hand = next(iter(val_dl))\n",
    "        pitch_logits, hand_logits = model(feats)\n",
    "        ce = F.cross_entropy(pitch_logits.view(-1, pitch_logits.size(-1)), labels.view(-1), ignore_index=88)\n",
    "        bce = F.binary_cross_entropy_with_logits(hand_logits.view(-1), hand.view(-1))\n",
    "        print('val ce', ce.item(), 'val bce', bce.item())\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0db027288813480da273afe8b8ed72b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14c238db74fa4b69a17f93ca93070cf5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20f87f86552842bd98911ac94518a220": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_70142856a4564001a45af49f49decb94",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_beeadd20ede74858a64be0f58e04b8c9",
      "value": 0
     }
    },
    "2b1873d60b214309adbb611b1fe82c1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_964a7273c99741518c8077465fbd531d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f261f547d12540c5917557d4314dda53",
      "value": "Sanityâ€‡Checkingâ€‡DataLoaderâ€‡0:â€‡100%"
     }
    },
    "2b37bf2ade904891aa25194d2e702a5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14c238db74fa4b69a17f93ca93070cf5",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_50e3849b19b149ec998706cdf84b5841",
      "value": 1
     }
    },
    "2e5f320a92fd47b3960e4eb428cae7a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": "100%"
     }
    },
    "3b9bc89a9fe04ddcbc9bdae3f92d1c23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee2a89171abb4dc9b516d3bb9d28252a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_7be06661bcbb42ae8c24c6a2b0912245",
      "value": "â€‡2/2â€‡[00:01&lt;00:00,â€‡â€‡1.32it/s]"
     }
    },
    "49bc04f9cad9408a98eef18494359475": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_613552f04b5041dfb8f234a918122ec6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_92ec3604c9184ab0b0d81eeb9b745cea",
      "value": "â€‡0/32â€‡[00:00&lt;?,â€‡?it/s]"
     }
    },
    "50e3849b19b149ec998706cdf84b5841": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "52e9e34e29d84a6eaec621a784405845": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "613552f04b5041dfb8f234a918122ec6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70142856a4564001a45af49f49decb94": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7be06661bcbb42ae8c24c6a2b0912245": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8688d24f3c964849a3726be1e19794a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_df9d77510a5344fda0fa76e29e9f0080",
       "IPY_MODEL_20f87f86552842bd98911ac94518a220",
       "IPY_MODEL_49bc04f9cad9408a98eef18494359475"
      ],
      "layout": "IPY_MODEL_d7aa1d71fafe429f859e751e02606cad"
     }
    },
    "92ec3604c9184ab0b0d81eeb9b745cea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "964a7273c99741518c8077465fbd531d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "beeadd20ede74858a64be0f58e04b8c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d7aa1d71fafe429f859e751e02606cad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "df9d77510a5344fda0fa76e29e9f0080": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52e9e34e29d84a6eaec621a784405845",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0db027288813480da273afe8b8ed72b5",
      "value": "Epochâ€‡0:â€‡â€‡â€‡0%"
     }
    },
    "eb476f83858344a39ae8e2f94bd3ea99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2b1873d60b214309adbb611b1fe82c1f",
       "IPY_MODEL_2b37bf2ade904891aa25194d2e702a5e",
       "IPY_MODEL_3b9bc89a9fe04ddcbc9bdae3f92d1c23"
      ],
      "layout": "IPY_MODEL_2e5f320a92fd47b3960e4eb428cae7a3"
     }
    },
    "ee2a89171abb4dc9b516d3bb9d28252a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f261f547d12540c5917557d4314dda53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
